---
title: "Spatial Distribution of Council Decisions"
author: "Benedikt Pilgram"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
    code_folding: hide
    theme: flatly
    highlight: tango
    html_document: /Users/benedikt.pilgram/Code/Geomodelierung/docs/report_bp.html
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.width = 10,
  fig.height = 6
)

# Load required packages
library(tidyverse)
library(sf)
library(leaflet)
library(knitr)
```

# Abstract

This project demonstrates the spatial distribution of council decisions in Augsburg, Germany. By extracting location references from council papers (OParl data) and matching them against a street gazetteer, we identify where council are geographically focused. The study combines natural language processing (fuzzy string matching) with interactive mapping to visualize the political negotiation of urban space. K

# 1. Introduction

## 1.1 Background

Municipal councils shape urban development through formal decisions documented in official records. Understanding where political attention is concentrated provides insights into urban governance priorities and spatial inequalities.

In Augsburg (population \~295,000), the city council approves development plans (BebauungsplÃ¤ne), building permits, and infrastructure projects. These are documented in the OParl API, a standardized platform for publishing municipal legislative information.

## 1.2 Research Question

> **"**What geographically relevant information, such as development plans and infrastructure projects in Augsburg, was discussed politically in the council minutes?**"**

## 1.3 Objectives

1.  Develop a reproducible pipeline to extract location references from council papers
2.  Create a street gazetteer for Augsburg with geocoded coordinates
3.  Match council papers to geographic locations using fuzzy string matching
4.  Visualize results on an interactive map with temporal metadata

# 2. Study Area

**Augsburg, Bavaria, Germany** - Population: \~295,000 (city proper) - Metropolitan area: \~800,000 - Historical context: Roman city (2,000 years), medieval trading hub, industrial heritage - Administrative structure: City Council (Stadtrat) with 60 members - Data source: ALLRIS OParl API (<https://augsburg.de/oparl/v1.0>)

### Geographic Scope

Analysis limited to streets and locations within Augsburg city boundaries. A gazetteer of street names and locaitons was extracted from OpenStreetMap (Overpass API) for matching against council papers.

# 3. Data and Methods

## 3.1 Data Sources

### OParl Council Records

-   **Source**: ALLRIS OParl API (Augsburg municipal system)
-   **Content**: Council papers (Drucksachen), agendas, decisions
-   **Format**: JSON API responses with full-text PDF access
-   **Coverage**: sample limited to 10 papers for this analysis
-   **Metadata**: Paper ID, title, date, main file (PDF), URL references

### OpenStreetMap Street Data

-   **Source**: Overpass API query for ways tagged with `["highway"]["name"]` within Augsburg bounding box
-   **Processing**: 12,641 street segments extracted â†’ 3,120 unique street names after deduplication
-   **Data quality**: Coordinates taken from segment midpoints (representative, not exact boundaries)

### PDF Text Extraction

-   **Tool**: `pdftools` R package (wrapper around pdftotext)
-   **Filter**: PDFs â‰¤10 pages (to avoid overly large documents)
-   **Sample**: 8 papers downloaded and processed

## 3.2 Methods

### 3.2.1 Gazetteer Creation (Script: `01_gazetteer.R`)

**Step 1: Bounding Box Retrieval** - Query Nominatim API with city name and country - Extract bounding box coordinates (south, north, west, east)

**Step 2: Street Data Acquisition** - Query Overpass API for all highway features with names within bounding box - OverpassQL query: `way["highway"]["name"](bbox)` - Response format: GeoJSON with street names and center coordinates

**Step 3: Deduplication** - Group by street name, retain first occurrence - Remove duplicates while preserving geographic coordinates - Sort alphabetically for consistency

**Step 4: Output** - CSV with columns: `street_name`, `latitude`, `longitude` - Used as reference database for subsequent location matching

### 3.2.2 PDF Download and Metadata (Script: `02_fetch_papers.R`)

**Step 1: OParl Navigation** - Fetch System â†’ Body â†’ Paper endpoints - Extract paper metadata: title, date, main file URL

**Step 2: PDF Download** - Iterate through papers, fetch mainFile via HTTP - Check file size constraints (max 10 pages via pdf_info) - Store in `data/pdfs/` with paper ID as filename

**Step 3: Metadata Logging** - Record: `paper_id`, `paper_title`, `paper_date`, `pdf_url`, `pdf_path`, `page_count` - Export to CSV for downstream processing

### 3.2.3 Location Extraction (Script: `03_extract_locations.R`)

**Step 1: Text Extraction** - Use `pdftools::pdf_text()` to extract full text from each PDF - Concatenate all pages into single string

**Step 2: Fuzzy String Matching** - Split extracted text into words - For each street in gazetteer, compute Levenshtein distance to text words - Threshold: distance â‰¤ 0.2 (80% similarity match) - Captures variations: "Maximilianstr." â†’ "MaximilianstraÃŸe"

**Step 3: Match Quality Assessment** - Calculate match score: `1 - (distance / street_name_length)` - Retain only matches with score â‰¥ 0.8 - Log all matches with metadata

**Step 4: Output** - CSV: `paper_id`, `paper_title`, `paper_date`, `street_name`, `latitude`, `longitude`, `match_score`, `pdf_url`

### 3.2.4 Visualization (Script: `04_visualize.R`)

**Step 1: Map Creation** - Use Leaflet JS library (via R htmlwidgets) - Base layer: OpenStreetMap + CartoDB Dark/Light options - Center: Median of all extracted coordinates

**Step 2: Markers and Clusters** - Circle markers for each location match - Size: Fixed 8px radius - Color: Red (#f44336) with 0.7 opacity - Clustering: Markercluster plugin (maxClusterRadius=50)

**Step 3: Popups** - Interactive popups with: - Street name - Paper title (truncated to 100 chars) - Paper date - Match score (85-100%) - Clickable link to PDF

**Step 4: Output** - HTML file: `figures/interactive_map.html` - Self-contained or with assets folder (depending on pandoc availability) - Browser-compatible: all modern browsers supported

# 4. Results

## 4.1 Gazetteer Statistics

```{r, eval=FALSE}
# Example output from 01_gazetteer.R
# âœ“ Gefunden: 12,641 StraÃŸensegmente
# âœ“ Verarbeitet: 3,120 eindeutige StraÃŸen
# Preview (first 5 streets):
#   street_name            latitude  longitude
# 1 Aachener StraÃŸe       48.3521  10.8951
# 2 Ackermann StraÃŸe      48.3634  10.8723
# 3 Ã„ussere UferstraÃŸe    48.3701  10.8845
# 4 AgnesstraÃŸe           48.3578  10.9034
# 5 Agneswalder StraÃŸe    48.3612  10.8876
```

**Findings:** - 3,120 unique street names across Augsburg - Average 4.0 segments per street (12,641 / 3,120) - Geographic coverage: entire city area

## 4.2 PDF Download Results

```{r, eval=FALSE}
# Example output from 02_fetch_papers.R
# âœ“ Heruntergeladen: 8 PDFs
# â†’ Ãœbersprungen: 2
# Durchschnittliche Seitenzahl: 2.1
```

**Quality Control:** - Filter threshold: 10 pages maximum - Skipped papers: 41-page development plan (too large) - Downloaded papers: 1-3 pages (typical council papers)

## 4.3 Location Extraction Results

```{r, eval=FALSE}
# Example output from 03_extract_locations.R
# Papers processed: 8
# Locations found: 12
# Unique streets mentioned: 8
# Average match score: 0.92
```

**Match Examples:** - "FuggerstraÃŸe" in paper title + document â†’ 100% match - "Maximilianstr." in text â†’ fuzzy match to "MaximilianstraÃŸe" (0.88) - False positives prevented by threshold (e.g., "StraÃŸe" alone rejected)

## 4.4 Interactive Map

```{r map, fig.width=12, fig.height=8}
# Lade die extrahierten Locations
if (file.exists("../data/extracted_locations.csv")) {
  locations <- read.csv("../data/extracted_locations.csv",
                        stringsAsFactors = FALSE,
                        fileEncoding = "UTF-8")

  # Filter: Nur Matches â‰¥ 85%
  min_match_score <- 0.85
  locations_filtered <- locations[locations$match_score >= min_match_score, ]

  if (nrow(locations_filtered) > 0) {
    # Center berechnen
    center_lat <- median(locations_filtered$latitude, na.rm = TRUE)
    center_lon <- median(locations_filtered$longitude, na.rm = TRUE)

    # Popup erstellen
    locations_filtered <- locations_filtered %>%
      mutate(
        popup_text = sprintf(
          "<div style='font-family: Arial, sans-serif; max-width: 300px;'>
            <h4 style='margin: 0 0 10px 0; color: #d32f2f;'>%s</h4>
            <p style='margin: 5px 0;'><strong>Paper:</strong><br>%s</p>
            <p style='margin: 5px 0;'><strong>Datum:</strong> %s</p>
            <p style='margin: 5px 0;'><strong>Match:</strong> %.0f%%</p>
            <a href='%s' target='_blank' style='display: inline-block; margin-top: 10px; padding: 5px 10px; background: #1976d2; color: white; text-decoration: none; border-radius: 3px;'>
              ðŸ“„ PDF Ã¶ffnen
            </a>
          </div>",
          street_name,
          substr(paper_title, 1, 100),
          ifelse(is.na(paper_date), "k.A.", paper_date),
          match_score * 100,
          pdf_url
        )
      )

    # Leaflet Karte
    leaflet(locations_filtered) %>%
      addTiles(group = "OpenStreetMap") %>%
      addProviderTiles(providers$CartoDB.Positron, group = "Hell") %>%
      addProviderTiles(providers$CartoDB.DarkMatter, group = "Dunkel") %>%
      setView(lng = center_lon, lat = center_lat, zoom = 13) %>%
      addCircleMarkers(
        lng = ~longitude,
        lat = ~latitude,
        popup = ~popup_text,
        radius = 8,
        color = "#d32f2f",
        fillColor = "#f44336",
        fillOpacity = 0.7,
        stroke = TRUE,
        weight = 2,
        clusterOptions = markerClusterOptions(
          maxClusterRadius = 50,
          spiderfyOnMaxZoom = TRUE
        )
      ) %>%
      addLayersControl(
        baseGroups = c("OpenStreetMap", "Hell", "Dunkel"),
        options = layersControlOptions(collapsed = FALSE)
      ) %>%
      addControl(
        html = sprintf(
          "<div style='background: white; padding: 10px; border-radius: 5px; box-shadow: 0 2px 5px rgba(0,0,0,0.2);'>
            <h3 style='margin: 0 0 5px 0;'>Augsburg - Policy Focus Areas</h3>
            <p style='margin: 0; font-size: 14px;'>%d Locations aus %d Papers<br>(Match â‰¥ 85%%)</p>
          </div>",
          nrow(locations_filtered),
          length(unique(locations_filtered$paper_id))
        ),
        position = "topright"
      )
  } else {
    cat("**Hinweis**: Keine Locations mit â‰¥85% Match gefunden. Bitte 03_extract_locations.R ausfÃ¼hren.")
  }
} else {
  cat("**Hinweis**: Locations-Datei nicht gefunden. Bitte 03_extract_locations.R ausfÃ¼hren.")
}
```

**Karteninteraktion:** - **Zoomen**: Scroll oder +/- Buttons - **Verschieben**: Klick & Drag - **Cluster**: Klick auf Cluster zum Aufteilen - **Layer**: Wechsel zwischen OpenStreetMap, Hell, Dunkel - **Popups**: Klick auf Marker fÃ¼r Details und PDF-Link

# 5. Discussion

## 5.1 Methodology Strengths

1.  **Reproducibility**: All steps documented and automated via scripts
2.  **Transparency**: Fuzzy matching parameters explicit and tunable
3.  **Data availability**: OParl (partially) and OpenStreetMap are public, reusable for other cities
4.  **Scalability**: Theoretically scalable for hundreds of papers

## 5.2 Limitations

1.  **PDF text quality**: Scanned PDFs without OCR will fail (mitigation: OCR not yet implemented)
2.  **Fuzzy matching and Gazetteer**: Misses location references. And adds irrelevant information. Better fine-tuning required.
3.  **Size and clarity**: This pilot uses only 8 papers; full analysis 100+ for statistical power come with compromises and considerations for the application. Adjustment of the layout, e.g. drop-down menu.

## 5.3 Interpretation

Due to the existing challenges, it is difficult to draw a final conclusion. Focusing on meta data together with scaling could be one option. However, thanks to technological advances, working with political data at the local level certainly holds potential for human geography, for example in fields such as urban development.

## 5.4 Future Work

A few ideas and examples: **Scale up**: Process all 2,000+ available papers, **Temporal analysis**: Map locations over time (heatmaps, animations), **OCR integration**: Handle scanned PDFs, **Network analysis**: Connect related papers and locations, **Comparative study**: Replicate methodology in other German cities, **Policy outcomes**: Link council discussions to actual development outcomes and **NLP enhancement**: Use named entity recognition (NER) instead of fuzzy matching.

I see the greatest potential in the connection with Linked Open Data, both for scientific purposes and for the benefit of citizens. Keywords here are RFG and GeoSPARQL.Â 

# 6. Conclusion

This study demonstrates a practical pipeline for extracting and visualizing geographic information embedded in municipal council documents. By combining OParl APIs, OpenStreetMap data, and fuzzy string matching, we create a reproducible workflow for understanding spatial dimensions of urban governance.

The resulting interactive map could provide city planners, researchers, and citizens with a novel tool for analyzing where and when policy discussions occur in the future. While this pilot analysis is limited in scope, the methodology is scalable and adaptable to other municipalities.

**Key takeaway**: Making spatial information in council records visible enables better understanding of political priorities, equity in resource allocation, and patterns in urban development discourse.

------------------------------------------------------------------------

# 7. Technical Appendix

## 7.1 System Requirements

-   **R** â‰¥ 4.0
-   **Packages**: httr, jsonlite, dplyr, pdftools, yaml, leaflet, htmlwidgets, stringdist
-   **External tools**: Pandoc (optional, for selfcontained HTML output)
-   **OS**: macOS, Linux, Windows

## 7.2 Configuration (config.yaml)

``` yaml
# City information
city: Augsburg
country: Deutschland

# Gazetteer settings
max_streets: 10000

# OParl API
oparl_api: "https://augsburg.de/oparl/v1.0"

# Paper download limits
max_papers: 10
max_pages_per_pdf: 10
```

## 7.3 Running the Pipeline

``` bash
# Option 1: From RStudio (Open geomodelierung.Rproj first)
source("analysis/run_all.r", encoding = "UTF-8")

# Option 2: From terminal
Rscript analysis/run_all.r

# Option 3: Individual scripts
Rscript R/01_gazetteer.r
Rscript R/02_fetch_papers.r
Rscript R/03_extract_locations.r
Rscript R/04_visualize.r
```

## 7.4 Output Files

| File                           | Description                            |
|--------------------------------|----------------------------------------|
| `data/gazetteer/streets.csv`   | Augsburg street names with coordinates |
| `data/pdfs/*.pdf`              | Downloaded council papers              |
| `data/papers_metadata.csv`     | Paper metadata and download info       |
| `data/extracted_locations.csv` | Matched locations with scores          |
| `figures/interactive_map.html` | Final visualization                    |

# References

-   OParl Standard: <https://oparl.org/>

-   OpenStreetMap: <https://www.openstreetmap.org/>

-   Overpass API: <https://overpass-api.de/>

-   Leaflet JS: <https://leafletjs.com/>

-   R htmlwidgets: <https://www.htmlwidgets.org/>

-   Fuzzy String Matching: Levenshtein, V. (1966). "Binary codes capable of correcting deletions, insertions, and reversals"

-   [@birghan2019]
